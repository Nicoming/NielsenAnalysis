#Generates Urls from ISBNs
ISBNs = []
data = []
import io
with io.open('P5.csv','r',encoding='utf-8',errors='ignore') as f:
    #Errors='ignore' causes truncation of foreign characters, since linux environment has strict restrictions on encoding types
    #If you are using windows, simply using line in open('filename') will run and preserve original characters
    #Note: no books are actually omitted, it's merely the strings containing foreign characters
    for line in f:
        newLine = []
        for item in line.split(','):
            newLine.append(item.strip())
        newLine = list(filter(None, newLine))  # Elimnating empty elements somehow generated by parsing by ','
        for i in range(9-len(newLine)):
            newLine.append('NA')
        ISBNs.append(newLine[0])
        data.append(newLine)
print(ISBNs[0],ISBNs[1],ISBNs[2],ISBNs[-1])

print(data[0],data[1],data[2],data[-1])
'''''''''
from unidecode import unidecode
for line in open('P5.csv'):
    newLine = []
    for item in line.encode('cp932',errors='ignore').decode('cp932',errors='ignore').split(','):
        newLine.append(item.strip())
    newLine = list(filter(None, newLine))  # Elimnating empty elements somehow generated by parsing by ','
    ISBN = newLine[0]
    ISBNs.append(ISBN)
'''''
print(ISBNs[0])
print(ISBNs[-1])
print(len(ISBNs))

ROOT = 'https://www.amazon.co.uk/s/ref=nb_sb_noss?url=search-alias%3Daps&field-keywords='
print('File read, commencing scraping')
