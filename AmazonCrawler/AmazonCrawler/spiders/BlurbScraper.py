import scrapy
from lxml import html
from scrapy_splash import SplashRequest
class BlurbScraper(scrapy.Spider): #This spider inherits properties of scrapy class
    name = "blurbs" #Refer this spider by "blurbs" in terminals
    ISBNs = []
    data = []
    urls = []
    ROOT = "https://www.amazon.co.uk/s/ref=nb_sb_noss?url=search-alias%3Daps&field-keywords="
    BLURPPATH = '//*[@id="bookDescription_feature_div"]/text()'
    REVIEWPATH = '//*[@id="cr-medley-top-reviews-wrapper"]/text()'
    LANGPATH = '/ html / body / div[2] / div[2] / div[4] / div[18] / table / tbody / tr / td / div / ul / li[4] / b'
    URLPATH = "/html/body/div[1]/div[2]/div/div[3]/div[2]/div/div[4]/div[1]/div/ul/li/div/div/div/div[2]/div[1]/div[1]/a/@href"
    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'}
    def start_requests(self):
        self.data = self.readData('P5.csv')[0]
        self.ISBNs = self.readData('P5.csv')[1]
        for item in self.ISBNs:
            self.urls.append(self.ROOT+item)
        for url in self.urls:
            yield SplashRequest(url=url, headers=self.headers,callback=self.parseSearch,args={'wait':0.5})
    def parseSearch(self, response):
        if response.urljoin(response.selector.xpath(self.URLPATH).extract_first()) is not None:
            bookPage = response.urljoin(response.selector.xpath(self.URLPATH).extract_first())
            yield SplashRequest(bookPage, headers=self.headers,callback=self.parseBook)
    def parseBook(self, response):
        #rendered = Render(request.url).frame.toHtml()
        #formatted = str(redenered.toAscii())
        #tree = html.fromstring(formatted)
        yield print(['info'],response.selector.xpath(self.LANGPATH),response.selector.xpath(self.BLURPPATH).extract(),response.xpath(self.REVIEWPATH).extract())
    def parseReview(self,response):
        yield print(['review:'],response.selector.xpath(self.REVIEWPATH).extract())
    def readData(self,filename):
        ISBNs = []
        data = []
        import io
        with io.open(filename, 'r', encoding='utf-8', errors='ignore') as f:
            # Errors='ignore' causes truncation of foreign characters, since linux environment has strict restrictions on encoding types
            # If you are using windows, simply using line in open('filename') will run and preserve original characters
            # Note: no books are actually omitted, it's merely the strings containing foreign characters
            for line in f:
                newLine = []
                for item in line.split(','):
                    newLine.append(item.strip())
                newLine = list(filter(None, newLine))  # Elimnating empty elements somehow generated by parsing by ','
                for i in range(9 - len(newLine)):
                    newLine.append('NA')
                ISBNs.append(newLine[0])
                data.append(newLine)
        return data, ISBNs
'''''''''
import sys
from PyQt4.QtGui import *
from PyQt4.QtCore import *
from PyQt.QtWebKit import *

class Render(QWebPage):
    def __init__(self):
        self.app = QApplication(sys.argv)
        QWebPage.__init__(self)
        self.loadFinished.connect(self.loadFinished)
        self.mainFrame().load(QUrl(url))
        self.app.exec_()

    def _loadFinished(self,result):
        self.frame = self.mainFrame()
        self.app.quit()
'''''''''
